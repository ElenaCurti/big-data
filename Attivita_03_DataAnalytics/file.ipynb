{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambiamenti climatici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "I dati usati in questa applicazione si trovano nella cartella [data](applicazione/data/). \n",
    "<ul>\n",
    "    <li>In original si trovano i file originali trovati su internet</li>\n",
    "    <li>In modified si trovano i file \"processati\"</li>\n",
    "</ul>\n",
    "\n",
    "## Dati sulle temperature e sulle stazioni geografiche\n",
    "I file contenenti i dati relativi alle temperature ([temperatures.dat](applicazione/data/original/temperatures.dat)) e alle stazioni geografiche ([stations.inv](applicazione/data/original/stations.inv)) sono stati trovati sul sito [National Centers for Environmental Information](https://www.ncei.noaa.gov/). Sono scaricabili al seguente link: https://www.ncei.noaa.gov/pub/data/ghcn/v4/ghcnm.tavg.latest.qcu.tar.gz <br>\n",
    "\n",
    "\n",
    "## Dati sui Paesi\n",
    "I file contenenti informazioni sui Paesi sono stati trovati su due repository di github: <br>\n",
    "- [fips_to_iso_country_codes.csv](applicazione/data/original/fips_to_iso_country_codes.csv) trovato al seguente link: https://github.com/mysociety/gaze/blob/master/data/fips-10-4-to-iso-country-codes.csv <br>\n",
    "- [countries_info.csv](applicazione/data/original/countries_info.csv) trovato al seguente link https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes/blob/master/all/all.csv <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_FOLDER = \"applicazione\" + os.path.sep + \"data\" + os.path.sep\n",
    "DATA_ORIGINAL_FOLDER = DATA_FOLDER + \"original\"+ os.path.sep\n",
    "DATA_MODIFIED_FOLDER = DATA_FOLDER + \"modified\"+ os.path.sep\n",
    "\n",
    "def aggiungi_linea_iniziale(path_file1, path_file2, headers=\"-\"):\n",
    "    \"\"\"Funzione che inserisce nel file path_file2 una linea vuota e il contenuto del file path_file1 \"\"\"\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    if path_file1 == path_file2:\n",
    "        with open(path_file1, 'r') as file: \n",
    "            originalContent = file.read() \n",
    "        with open(path_file2, 'w') as file2:\n",
    "            file2.write(headers + \"\\n\" + originalContent)\n",
    "    else:\n",
    "        with open(path_file1, 'r') as file, open(path_file2, 'w') as file2: \n",
    "            originalContent = file.read() \n",
    "            file.seek(0, 0) # Prima posizione            \n",
    "            file2.write(headers + \"\\n\")\n",
    "            file2.write(originalContent) \n",
    "    # print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "def crea_file_csv(file_originale, file_modificato, list_width, headers=\"\", column_to_drop=-1):\n",
    "    \"\"\"Funzione che crea un file CSV partendo da un Fixed Width Text File. \n",
    "    In input sono richiesti: \n",
    "    - Il path del file originale\n",
    "    - Il path del file CSV che verra' creat\n",
    "    - Lista delle lunghezze delle colonne di file_originale\"\"\"\n",
    "    if os.path.exists(file_modificato):\n",
    "        return\n",
    "    print(\"Creo file csv partendo da\",file_originale,\"...\")\n",
    "    file_tmp = file_originale + \"tmp\"\n",
    "    aggiungi_linea_iniziale(file_originale, file_tmp)\n",
    "    df = pd.read_fwf(file_tmp, widths=list_width)\n",
    "    if column_to_drop != -1:\n",
    "        df = df.drop(df.columns[column_to_drop], axis=1) \n",
    "    if str(file_originale).__contains__(\"stations\"):\n",
    "        print(df.columns[[0]])\n",
    "        df['fips'] = df[df.columns[0]].apply(lambda x : x[0:2])\n",
    "    df.to_csv(file_modificato, index=False, header=False)\n",
    "    if headers != \"\":\n",
    "        aggiungi_linea_iniziale(file_modificato, file_modificato, headers)\n",
    "\n",
    "    os.remove(file_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stazioni e temperature\n",
    "I file [stations.inv](applicazione/data/original/stations.inv) e [temperatures.dat](applicazione/data/original/temperatures.dat) trovati su internet sono Fixed Width Text File. Ho deciso di modificarli e convertirli in file CSV ([stations_created.csv](applicazione/data/modified/stations_created.csv), [tempetatures_created.csv](applicazione/data/modified/tempetatures_created.csv)) con la seguente struttura: <br>\n",
    "\n",
    "#### stations_created.csv\n",
    "\n",
    "|Campo| Significato|\n",
    "|:-|:-|\n",
    "|id_station| Codice identificativo della stazione. I primi due caratteri sono il codice FIPS del Paese|\n",
    "|latitude| Latitudine della stazione in gradi decimali|\n",
    "|longitude| Longitudine della stazione in gradi decimali|\n",
    "|st_elev| Altitudine della stazione in metri; il valore -999.0 indica un dato mancante|\n",
    "|name| Nome della stazione|\n",
    "|fips| Codice FIPS del Paese|\n",
    "\n",
    "#### tempetatures_created.csv\n",
    "\n",
    "|Campo| Significato|\n",
    "|:-|:-|\n",
    "|id_station| Codice identificativo della stazione. I primi due caratteri sono il codice FIPS del Paese|\n",
    "|year| Anno in cui sono state misurate le temperature|\n",
    "|month_value| Valore della temperatura del mese \"month\". I valori della temperatura sono in centesimi di grado Celsius, ma sono espressi come numeri interi (ad es. dividere per 100,0 per ottenere gradi Celsius interi). <br>Il valore -9999 indica un dato mancante. |\n",
    "|month_dm_flag| data measurement flag (indicatore della misurazione dei dati). <br>Se è vuoto -> nessuna informazione di misurazione applicabile <br> Se è una lettera tra a-i -> numero di giorni mancanti nel calcolo della temperatura media mensile |\n",
    "|month_qc_flag| quality control flag del mese \"month\". <br>Se è vuoto, non c'è stato nessun fallimento del controllo di qualità oppure il valore non può essere valutato. <br> Per gli altri valori, consultare la [documentazione dei dataset](https://www.ncei.noaa.gov/pub/data/ghcn/v4/readme.txt) |\n",
    "|month_ds_flag| Indica l'origine dati per il valore del mese \"month\". Per avere altre informazioni, consultare la [documentazione di tale campo](https://www.ncei.noaa.gov/pub/data/ghcn/v4/ghcnm-flags.txt)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho creato il seguente script per creare i due file CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creo file csv partendo da applicazione\\data\\original\\stations.inv ...\n",
      "Index(['-'], dtype='object')\n",
      "Files creati correttamente!\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "\n",
    "# File con le stazioni\n",
    "FILE_ORIGINALE_STATIONS = DATA_ORIGINAL_FOLDER + \"stations.inv\"\n",
    "FILE_CSV_STATIONS = DATA_MODIFIED_FOLDER + \"stations_created.csv\"\n",
    "headers =\"id_station,latitude,longitude,st_elev,name,fips\"\n",
    "crea_file_csv(FILE_ORIGINALE_STATIONS, FILE_CSV_STATIONS, [11,9,10,7,31], headers)\n",
    "\n",
    "# File con le temperature\n",
    "FILE_ORIGINALE_TEMPERATURES = DATA_ORIGINAL_FOLDER + \"temperatures.dat\"\n",
    "FILE_CSV_TEMPERATURES = DATA_MODIFIED_FOLDER + \"temperatures_created.csv\"\n",
    "\n",
    "list_width= [11,4,4]\n",
    "for _ in range(12):\n",
    "    list_width += [5,1,1,1]\n",
    "\n",
    "list_headers = [\"id_station\", \"year\",\"elem\"]\n",
    "for i in range(1,13):\n",
    "    month_name = calendar.month_name[i]\n",
    "    list_headers += [\"month:\"+month_name+\"_value\",\"month:\"+month_name+\"_dm_flag\",\"month:\"+month_name+\"_qc_flag\",\"month:\"+month_name+\"_ds_flag\"]\n",
    "headers = \",\".join(list_headers)\n",
    "crea_file_csv(FILE_ORIGINALE_TEMPERATURES, FILE_CSV_TEMPERATURES, list_width, headers,3)\n",
    "\n",
    "print(\"Files creati correttamente!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paesi\n",
    "Per quanto riguarda le informazioni sui paesi, ho unito i due file [country_info.csv](applicazione/data/original/countries_info.csv) e [fips_to_iso_country_codes.csv](applicazione/data/original/fips_to_iso_country_codes.csv) in un unico file [countries_created.csv](applicazione/data/original/countries_created.csv) con la seguente struttura:\n",
    "\n",
    "|Campo|Significato|\n",
    "|:-|:-|\n",
    "|name| Nome del Paese|\n",
    "|fips| Codice FIPS del paese|\n",
    "|region| Continente di appartenenza|\n",
    "|sub-region| Zona del continente (nord, sud, est, ovest)|\n",
    "|intermediate-region| Altre informazioni sul continente|\n",
    "|region-code| Codice di region|\n",
    "|sub-region-code| Codice di sub-region|\n",
    "|intermediate-region-code| Codice di intermediate-region|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: applicazione\\data\\original\\fips_to_iso_country_codes.csv \t 272\n",
      "file: applicazione\\data\\original\\countries_info.csv \t\t 249\n",
      "file: applicazione\\data\\modified\\stations_created.csv \t\t 237\n",
      "---\n",
      "  FIPS 10-4 ISO 3166            Name            name alpha-2 alpha-3  \\\n",
      "0        AF       AF     Afghanistan     Afghanistan      AF     AFG   \n",
      "1        AX        -        Akrotiri             NaN     NaN     NaN   \n",
      "2        AL       AL         Albania         Albania      AL     ALB   \n",
      "3        AG       DZ         Algeria         Algeria      DZ     DZA   \n",
      "4        AQ       AS  American Samoa  American Samoa      AS     ASM   \n",
      "\n",
      "   country-code     iso_3166-2   region       sub-region intermediate-region  \\\n",
      "0           4.0  ISO 3166-2:AF     Asia    Southern Asia                 NaN   \n",
      "1           NaN            NaN      NaN              NaN                 NaN   \n",
      "2           8.0  ISO 3166-2:AL   Europe  Southern Europe                 NaN   \n",
      "3          12.0  ISO 3166-2:DZ   Africa  Northern Africa                 NaN   \n",
      "4          16.0  ISO 3166-2:AS  Oceania        Polynesia                 NaN   \n",
      "\n",
      "   region-code  sub-region-code  intermediate-region-code  \n",
      "0        142.0             34.0                       NaN  \n",
      "1          NaN              NaN                       NaN  \n",
      "2        150.0             39.0                       NaN  \n",
      "3          2.0             15.0                       NaN  \n",
      "4          9.0             61.0                       NaN  \n",
      "279\n"
     ]
    }
   ],
   "source": [
    "FILE_ORIGINALE_FIPS_TO_ISO = DATA_ORIGINAL_FOLDER + \"fips_to_iso_country_codes.csv\"\n",
    "FILE_ORIGINALE_COUNTRY_INFO = DATA_ORIGINAL_FOLDER + \"countries_info.csv\"\n",
    "FILE_CSV_COUNTRIES_CREATED = DATA_MODIFIED_FOLDER + \"countries_created.csv\"\n",
    "\n",
    "# Leggo i files originali\n",
    "df_fips = pd.read_csv(FILE_ORIGINALE_FIPS_TO_ISO)\n",
    "print(\"file:\",FILE_ORIGINALE_FIPS_TO_ISO, \"\\t\", len(pd.unique(df_fips['FIPS 10-4'])))\n",
    "\n",
    "df_country = pd.read_csv(FILE_ORIGINALE_COUNTRY_INFO)\n",
    "print(\"file:\",FILE_ORIGINALE_COUNTRY_INFO, \"\\t\\t\", len(pd.unique(df_country['alpha-2'])))\n",
    "\n",
    "df_station = pd.read_csv(FILE_CSV_STATIONS)\n",
    "# print(\"---\\n\",df_country.head())\n",
    "print(\"file:\",FILE_CSV_STATIONS, \"\\t\\t\", len(pd.unique(df_station['fips'])))\n",
    "\n",
    "print(\"---\")\n",
    "# print(pd.merge(df_fips, df_country, how='cross', left_on='ISO 3166', right_on='alpha-2'))\n",
    "merged = pd.merge(df_fips, df_country, how='left',left_on='ISO 3166', right_on='alpha-2')\n",
    "print(merged.head())\n",
    "print(len(merged.axes[0]))\n",
    "# print(pd.merge(df_fips, df_country, left_on=1, right_on=1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a29d3b88d3d770f4c6b76b3f467a825cd9493448f3062cde152f1e267121f11d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
