{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambiamenti climatici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "I dati usati in questa applicazione si trovano nella cartella [data](applicazione/data/). \n",
    "<ul>\n",
    "    <li>In original si trovano i file originali trovati su internet</li>\n",
    "    <li>In modified si trovano i file \"processati\"</li>\n",
    "</ul>\n",
    "\n",
    "## Dati sulle temperature e sulle stazioni geografiche\n",
    "I file contenenti i dati relativi alle temperature ([temperatures.dat](applicazione/data/original/temperatures.dat)) e alle stazioni geografiche ([stations.inv](applicazione/data/original/stations.inv)) sono stati trovati sul sito [National Centers for Environmental Information](https://www.ncei.noaa.gov/). Sono scaricabili al seguente link: https://www.ncei.noaa.gov/pub/data/ghcn/v4/ghcnm.tavg.latest.qcu.tar.gz <br>\n",
    "\n",
    "\n",
    "## Dati sui Paesi\n",
    "I file contenenti informazioni sui Paesi sono stati trovati su due repository di github: <br>\n",
    "- [fips_to_iso_country_codes.csv](applicazione/data/original/fips_to_iso_country_codes.csv) trovato al seguente link: https://github.com/mysociety/gaze/blob/master/data/fips-10-4-to-iso-country-codes.csv <br>\n",
    "- [countries_info.csv](applicazione/data/original/countries_info.csv) trovato al seguente link https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes/blob/master/all/all.csv <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_FOLDER = \"applicazione\" + os.path.sep + \"data\" + os.path.sep\n",
    "DATA_ORIGINAL_FOLDER = DATA_FOLDER + \"original\"+ os.path.sep\n",
    "DATA_MODIFIED_FOLDER = DATA_FOLDER + \"modified\"+ os.path.sep\n",
    "\n",
    "def aggiungi_linea_iniziale(path_file1, path_file2, headers=\"-\"):\n",
    "    \"\"\"Funzione che inserisce nel file path_file2 una linea vuota e il contenuto del file path_file1 \"\"\"\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    if path_file1 == path_file2:\n",
    "        with open(path_file1, 'r') as file: \n",
    "            originalContent = file.read() \n",
    "        with open(path_file2, 'w') as file2:\n",
    "            file2.write(headers + \"\\n\" + originalContent)\n",
    "    else:\n",
    "        with open(path_file1, 'r') as file, open(path_file2, 'w') as file2: \n",
    "            originalContent = file.read() \n",
    "            file.seek(0, 0) # Prima posizione            \n",
    "            file2.write(headers + \"\\n\")\n",
    "            file2.write(originalContent) \n",
    "    # print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "def crea_file_csv(file_originale, file_modificato, list_width, headers=\"\", column_to_drop=-1, crea_campo_fips=False):\n",
    "    \"\"\"Funzione che crea un file CSV partendo da un Fixed Width Text File. \n",
    "    In input sono richiesti: \n",
    "    - Il path del file originale\n",
    "    - Il path del file CSV che verra' creat\n",
    "    - Lista delle lunghezze delle colonne di file_originale\"\"\"\n",
    "    if os.path.exists(file_modificato):\n",
    "        return\n",
    "    print(\"Creo file csv partendo da\",file_originale,\"...\")\n",
    "    file_tmp = file_originale + \"tmp\"\n",
    "    aggiungi_linea_iniziale(file_originale, file_tmp)\n",
    "    df = pd.read_fwf(file_tmp, widths=list_width)\n",
    "    if column_to_drop != -1:\n",
    "        df = df.drop(df.columns[column_to_drop], axis=1) \n",
    "    if crea_campo_fips:\n",
    "        df['fips'] = df[df.columns[0]].apply(lambda x : x[0:2])\n",
    "    df.to_csv(file_modificato, index=False, header=False)\n",
    "    if headers != \"\":\n",
    "        aggiungi_linea_iniziale(file_modificato, file_modificato, headers)\n",
    "\n",
    "    os.remove(file_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stazioni e temperature\n",
    "I file [stations.inv](applicazione/data/original/stations.inv) e [temperatures.dat](applicazione/data/original/temperatures.dat) trovati su internet sono Fixed Width Text File. Ho deciso di modificarli e convertirli in file CSV ([stations_created.csv](applicazione/data/modified/stations_created.csv), [tempetatures_created.csv](applicazione/data/modified/tempetatures_created.csv)) con la seguente struttura: <br>\n",
    "\n",
    "#### stations_created.csv\n",
    "\n",
    "|Campo| Significato|\n",
    "|:-|:-|\n",
    "|id_station| Codice identificativo della stazione. I primi due caratteri sono il codice FIPS del Paese|\n",
    "|latitude| Latitudine della stazione in gradi decimali|\n",
    "|longitude| Longitudine della stazione in gradi decimali|\n",
    "|st_elev| Altitudine della stazione in metri; il valore -999.0 indica un dato mancante|\n",
    "|name| Nome della stazione|\n",
    "|fips| Codice FIPS del Paese|\n",
    "\n",
    "#### tempetatures_created.csv\n",
    "\n",
    "|Campo| Significato|\n",
    "|:-|:-|\n",
    "|id_station| Codice identificativo della stazione. I primi due caratteri sono il codice FIPS del Paese|\n",
    "|year| Anno in cui sono state misurate le temperature|\n",
    "|month_value| Valore della temperatura del mese \"month\". I valori della temperatura sono in centesimi di grado Celsius, ma sono espressi come numeri interi (ad es. dividere per 100,0 per ottenere gradi Celsius interi). <br>Il valore -9999 indica un dato mancante. |\n",
    "|month_dm_flag| data measurement flag (indicatore della misurazione dei dati). <br>Se è vuoto -> nessuna informazione di misurazione applicabile <br> Se è una lettera tra a-i -> numero di giorni mancanti nel calcolo della temperatura media mensile |\n",
    "|month_qc_flag| quality control flag del mese \"month\". <br>Se è vuoto, non c'è stato nessun fallimento del controllo di qualità oppure il valore non può essere valutato. <br> Per gli altri valori, consultare la [documentazione dei dataset](https://www.ncei.noaa.gov/pub/data/ghcn/v4/readme.txt) |\n",
    "|month_ds_flag| Indica l'origine dati per il valore del mese \"month\". Per avere altre informazioni, consultare la [documentazione di tale campo](https://www.ncei.noaa.gov/pub/data/ghcn/v4/ghcnm-flags.txt)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho creato il seguente script per creare i due file CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creo file csv partendo da applicazione\\data\\original\\stations.inv ...\n",
      "Creo file csv partendo da applicazione\\data\\original\\temperatures.dat ...\n",
      "Files creati correttamente!\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "\n",
    "# File con le stazioni\n",
    "FILE_ORIGINALE_STATIONS = DATA_ORIGINAL_FOLDER + \"stations.inv\"\n",
    "FILE_CSV_STATIONS = DATA_MODIFIED_FOLDER + \"stations_created.csv\"\n",
    "headers =\"id_station,latitude,longitude,st_elev,name,fips\"\n",
    "crea_file_csv(FILE_ORIGINALE_STATIONS, FILE_CSV_STATIONS, [11,9,10,7,31], headers, crea_campo_fips=True)\n",
    "\n",
    "# File con le temperature\n",
    "FILE_ORIGINALE_TEMPERATURES = DATA_ORIGINAL_FOLDER + \"temperatures.dat\"\n",
    "FILE_CSV_TEMPERATURES = DATA_MODIFIED_FOLDER + \"temperatures_created.csv\"\n",
    "\n",
    "list_width= [11,4,4]\n",
    "for _ in range(12):\n",
    "    list_width += [5,1,1,1]\n",
    "\n",
    "list_headers = [\"id_station\", \"year\",\"elem\"]\n",
    "for i in range(1,13):\n",
    "    month_name = calendar.month_name[i]\n",
    "    list_headers += [\"month:\"+month_name+\"_value\",\"month:\"+month_name+\"_dm_flag\",\"month:\"+month_name+\"_qc_flag\",\"month:\"+month_name+\"_ds_flag\"]\n",
    "headers = \",\".join(list_headers)\n",
    "crea_file_csv(FILE_ORIGINALE_TEMPERATURES, FILE_CSV_TEMPERATURES, list_width, headers,3)\n",
    "\n",
    "print(\"Files creati correttamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paesi\n",
    "Per quanto riguarda le informazioni sui paesi, ho unito i due file [country_info.csv](applicazione/data/original/countries_info.csv) e [fips_to_iso_country_codes.csv](applicazione/data/original/fips_to_iso_country_codes.csv) in un unico file [countries_created.csv](applicazione/data/original/countries_created.csv) con la seguente struttura:\n",
    "\n",
    "|Campo|Significato|\n",
    "|:-|:-|\n",
    "|fips| Codice FIPS del paese|\n",
    "|name_country| Nome del Paese|\n",
    "|region| Continente di appartenenza|\n",
    "|sub-region| Zona del continente (nord, sud, est, ovest)|\n",
    "|region-code| Codice di region|\n",
    "|sub-region-code| Codice di sub-region|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File creato correttamente!\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "FILE_ORIGINALE_FIPS_TO_ISO = DATA_ORIGINAL_FOLDER + \"fips_to_iso_country_codes.csv\"\n",
    "FILE_ORIGINALE_COUNTRY_INFO = DATA_ORIGINAL_FOLDER + \"countries_info.csv\"\n",
    "FILE_CSV_COUNTRIES_CREATED = DATA_MODIFIED_FOLDER + \"countries_created.csv\"\n",
    "\n",
    "# Leggo i files originali\n",
    "df_fips = pd.read_csv(FILE_ORIGINALE_FIPS_TO_ISO)\n",
    "df_country = pd.read_csv(FILE_ORIGINALE_COUNTRY_INFO)\n",
    "\n",
    "# Li unisco in base al codice alpha\n",
    "merged = pd.merge(df_fips, df_country, how='left',left_on='ISO 3166', right_on='alpha-2')\n",
    "\n",
    "# Elimino le colonne non necessarie e rinomino le altre\n",
    "merged = merged.drop(['ISO 3166','iso_3166-2', 'alpha-3', 'alpha-2', 'country-code', 'intermediate-region', 'intermediate-region-code'], axis=1)\n",
    "merged['name_country'] = merged.apply(lambda x : str(x['Name'] if str(x[\"name\"]).lower() == \"nan\" else x['name']), axis=1)\n",
    "merged = merged.drop([ 'name', 'Name'], axis=1)\n",
    "merged = merged.rename(columns={\"FIPS 10-4\":\"fips\"})\n",
    "\n",
    "# e creo un nuovo file\n",
    "merged.to_csv(FILE_CSV_COUNTRIES_CREATED, index=False, header=True)\n",
    "\n",
    "print(\"File creato correttamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for index, row in merged.iterrows():\n",
    "#     print(f\"{index:5}\", f\"{row['name']:50}\",row['fips'])\n",
    "\n",
    "\n",
    "# print(merged)\n",
    "\n",
    "df_stations = pd.read_csv(FILE_CSV_STATIONS)\n",
    "# print(len(pd.unique(df_stations['fips'])))\n",
    "\n",
    "merged2 = df_stations.merge(merged, how='left', on='fips')\n",
    "# merged2 = merged2.drop(['name_country', 'region', 'sub-region', 'region-code', 'sub-region-code'], axis=1)\n",
    "merged2 = merged2.drop_duplicates() \n",
    "merged2 = merged2.reset_index()\n",
    "\n",
    "# print(merged2)\n",
    "for index, row in merged2.iterrows():\n",
    "    print(str(row).replace(\"\\n\",\"\\t\",-1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a29d3b88d3d770f4c6b76b3f467a825cd9493448f3062cde152f1e267121f11d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
