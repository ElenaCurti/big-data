{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambiamenti climatici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisiti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\utente\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\utente\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\utente\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\utente\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\utente\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\utente\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "I dati usati in questa applicazione si trovano nella cartella [data](applicazione/data/). \n",
    "<ul>\n",
    "    <li>In original si trovano i file originali trovati su internet</li>\n",
    "    <li>In modified si trovano i file \"processati\"</li>\n",
    "</ul>\n",
    "\n",
    "## Dati sulle temperature e sulle stazioni geografiche\n",
    "I file contenenti i dati relativi alle temperature ([temperatures.dat](applicazione/data/original/temperatures.dat)) e alle stazioni geografiche ([stations.inv](applicazione/data/original/stations.inv)) sono stati trovati sul sito [National Centers for Environmental Information](https://www.ncei.noaa.gov/). Sono scaricabili al seguente link: https://www.ncei.noaa.gov/pub/data/ghcn/v4/ghcnm.tavg.latest.qcf.tar.gz <br>\n",
    "\n",
    "\n",
    "## Dati sui Paesi\n",
    "I file contenenti informazioni sui Paesi sono stati trovati su due repository di github: <br>\n",
    "- [fips_to_iso_country_codes.csv](applicazione/data/original/fips_to_iso_country_codes.csv) trovato al seguente link: https://github.com/mysociety/gaze/blob/master/data/fips-10-4-to-iso-country-codes.csv <br>\n",
    "- [countries_info.csv](applicazione/data/original/countries_info.csv) trovato al seguente link https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes/blob/master/all/all.csv <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_FOLDER = \"applicazione\" + os.path.sep + \"data\" + os.path.sep\n",
    "DATA_ORIGINAL_FOLDER = DATA_FOLDER + \"original\"+ os.path.sep\n",
    "DATA_MODIFIED_FOLDER = DATA_FOLDER + \"modified\"+ os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stazioni e temperature\n",
    "I file [stations.inv](applicazione/data/original/stations.inv) e [temperatures.dat](applicazione/data/original/temperatures.dat) trovati su internet sono Fixed Width Text File. Ho deciso di modificarli e convertirli in file CSV ([stations_created.csv](applicazione/data/modified/stations_created.csv), [tempetatures_created.csv](applicazione/data/modified/tempetatures_created.csv)). In questo modo creo due file CSV con i dati già \"puliti\" e pronti per essere letti. Inoltre, la funzione read_csv per leggere file CSV è molto più veloce di read_fwf per leggere file Fixed Width, quindi <mark> continua... </mark>\n",
    "<br>\n",
    "\n",
    "#### Stazioni\n",
    "Il file [stations_created.csv](applicazione/data/modified/stations_created.csv) ha la seguente struttura:\n",
    "|Campo| Significato|\n",
    "|:-|:-|\n",
    "|station_id| Codice identificativo della stazione. I primi due caratteri sono il codice FIPS del Paese|\n",
    "|latitude| Latitudine della stazione in gradi decimali|\n",
    "|longitude| Longitudine della stazione in gradi decimali|\n",
    "|station_elev| Altitudine della stazione in metri; il valore -999.0 indica un dato mancante|\n",
    "|station_name| Nome della stazione|\n",
    "|fips| Codice FIPS del Paese|\n",
    "\n",
    "Ho creato uno script per creare il file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creo file csv partendo da applicazione\\data\\original\\stations.inv ...\n",
      "File creato correttamente!\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "\n",
    "# File con le stazioni\n",
    "FILE_ORIGINALE_STATIONS = DATA_ORIGINAL_FOLDER + \"stations.inv\"\n",
    "FILE_CSV_STATIONS = DATA_MODIFIED_FOLDER + \"stations_created.csv\"\n",
    "HEADERS_STATIONS = [\"station_id\",\"latitude\",\"longitude\",\"station_elev\",\"station_name\"]\n",
    "\n",
    "if not os.path.exists(FILE_CSV_STATIONS):\n",
    "    print(\"Creo file csv partendo da\",FILE_ORIGINALE_STATIONS,\"...\")\n",
    "    \n",
    "    # Leggo il file\n",
    "    df = pd.read_fwf(FILE_ORIGINALE_STATIONS,widths=[11,9,10,7,31], header=None, names=HEADERS_STATIONS)\n",
    "    \n",
    "    # Aggiungo il campo fips\n",
    "    df['fips'] = df[\"station_id\"].apply(lambda x : x[0:2])\n",
    "    HEADERS_STATIONS += [\"fips\"]\n",
    "    \n",
    "    # Converto in formato CSV\n",
    "    df.to_csv(FILE_CSV_STATIONS, index=False)\n",
    "print(\"File creato correttamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tempetatures_created.csv\n",
    "Il file [tempetatures_created.csv](applicazione/data/modified/stations_created.csv) ha la seguente struttura:\n",
    "|Campo| Significato|\n",
    "|:-|:-|\n",
    "|station_id| Codice identificativo della stazione. I primi due caratteri sono il codice FIPS del Paese|\n",
    "|year| Anno in cui sono state misurate le temperature|\n",
    "|month_value| Valore della temperatura del mese \"month\". I valori della temperatura sono in centesimi di grado Celsius, ma sono espressi come numeri interi (ad es. dividere per 100,0 per ottenere gradi Celsius interi). <br>Il valore -9999 indica un dato mancante. |\n",
    "|month_dm_flag| data measurement flag (indicatore della misurazione dei dati). <br>Se è vuoto -> nessuna informazione di misurazione applicabile <br> Se è una lettera tra a-i -> numero di giorni mancanti nel calcolo della temperatura media mensile |\n",
    "|month_qc_flag| quality control flag del mese \"month\". <br> Se è vuoto, non c'è stato nessun fallimento del controllo di qualità oppure il valore non può essere valutato. <br> Per gli altri valori, consultare la [documentazione dei dataset]((https://www.ncei.noaa.gov/pub/data/ghcn/v4/readme.txt)) |\n",
    "|month_ds_flag| Indica l'origine dati per il valore del mese \"month\". Per avere altre informazioni, consultare la [documentazione di tale campo](https://www.ncei.noaa.gov/pub/data/ghcn/v4/ghcnm-flags.txt)|\n",
    "\n",
    "Ho creato uno script per creare il file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creo file csv partendo da applicazione\\data\\original\\temperatures.dat ...\n",
      "File creato correttamente!\n"
     ]
    }
   ],
   "source": [
    "# File con le temperature\n",
    "FILE_ORIGINALE_TEMPERATURES = DATA_ORIGINAL_FOLDER + \"temperatures.dat\"\n",
    "FILE_CSV_TEMPERATURES = DATA_MODIFIED_FOLDER + \"temperatures_created.csv\"\n",
    "\n",
    "# Creo due liste: una con le lunghezze dei campi e una con i nomi delle colonne\n",
    "list_width= [11,4,4] + [j for i in [[5,1,1,1] for _ in range(12)] for j in i] \n",
    "len(list_width)\n",
    "HEADERS_TEMPERATURES = [\"station_id\", \"year\", \"DEL_ME\"]\n",
    "for i in range(1,13):\n",
    "    month_name = calendar.month_name[i]\n",
    "    HEADERS_TEMPERATURES += [month_name+\"_value\",month_name+\"_dm_flag\",month_name+\"_qc_flag\",month_name+\"_ds_flag\"]\n",
    "\n",
    "if not os.path.exists(FILE_CSV_TEMPERATURES):\n",
    "    print(\"Creo file csv partendo da\",FILE_ORIGINALE_TEMPERATURES,\"...\")\n",
    "    \n",
    "    # Leggo il file\n",
    "    df = pd.read_fwf(FILE_ORIGINALE_TEMPERATURES, widths=list_width,header=None, names=HEADERS_TEMPERATURES)\n",
    "    \n",
    "    # Elimino le colonne non necessarie\n",
    "    df = df.drop(df.columns[2], axis=1) \n",
    "    HEADERS_TEMPERATURES.remove(\"DEL_ME\")\n",
    "\n",
    "    # Converto in formato CSV\n",
    "    df.to_csv(FILE_CSV_TEMPERATURES, index=False)\n",
    "\n",
    "print(\"File creato correttamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paesi\n",
    "Per quanto riguarda le informazioni sui paesi, ho unito i due file [country_info.csv](applicazione/data/original/countries_info.csv) e [fips_to_iso_country_codes.csv](applicazione/data/original/fips_to_iso_country_codes.csv) in un unico file [countries_created.csv](applicazione/data/original/countries_created.csv) con la seguente struttura:\n",
    "\n",
    "|Campo|Significato|\n",
    "|:-|:-|\n",
    "|fips| Codice FIPS del paese|\n",
    "|name_country| Nome del Paese|\n",
    "|region| Continente di appartenenza|\n",
    "|sub-region| Zona del continente (nord, sud, est, ovest)|\n",
    "|region-code| Codice di region|\n",
    "|sub-region-code| Codice di sub-region|\n",
    "\n",
    "Ho creato uno script per creare il file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creo file csv partendo da applicazione\\data\\original\\fips_to_iso_country_codes.csv e applicazione\\data\\original\\countries_info.csv ...\n",
      "File creato correttamente!\n"
     ]
    }
   ],
   "source": [
    "# File dei paesi\n",
    "FILE_ORIGINALE_FIPS_TO_ISO = DATA_ORIGINAL_FOLDER + \"fips_to_iso_country_codes.csv\"\n",
    "FILE_ORIGINALE_COUNTRY_INFO = DATA_ORIGINAL_FOLDER + \"countries_info.csv\"\n",
    "FILE_CSV_COUNTRIES_CREATED = DATA_MODIFIED_FOLDER + \"countries_created.csv\"\n",
    "\n",
    "if not os.path.exists(FILE_CSV_COUNTRIES_CREATED):\n",
    "    print(\"Creo file csv partendo da\",FILE_ORIGINALE_FIPS_TO_ISO, \"e\", FILE_ORIGINALE_COUNTRY_INFO,\"...\")\n",
    "\n",
    "    # Leggo i files originali\n",
    "    df_fips = pd.read_csv(FILE_ORIGINALE_FIPS_TO_ISO)\n",
    "    df_country = pd.read_csv(FILE_ORIGINALE_COUNTRY_INFO)\n",
    "\n",
    "    # Faccio il join sul codice alpha-2\n",
    "    merged = pd.merge(df_fips, df_country, how='left',left_on='ISO 3166', right_on='alpha-2')\n",
    "\n",
    "    # Elimino le colonne non necessarie e rinomino le altre\n",
    "    merged = merged.drop(['ISO 3166','iso_3166-2', 'alpha-3', 'alpha-2', 'country-code', 'intermediate-region', 'intermediate-region-code'], axis=1)\n",
    "    merged['name_country'] = merged.apply(lambda x : str(x['Name'] if pd.isna(x[\"name\"]) else x['name']), axis=1)\n",
    "    merged = merged.drop([ 'name', 'Name'], axis=1)\n",
    "    merged = merged.rename(columns={\"FIPS 10-4\":\"fips\"})\n",
    "\n",
    "    # e creo un nuovo file\n",
    "    merged.to_csv(FILE_CSV_COUNTRIES_CREATED, index=False, header=True)\n",
    "\n",
    "print(\"File creato correttamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta creati tutti i file CSV, per usarli basterà leggerli e fare il join sul campo 'fips' e 'station_id':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatues = pd.read_csv(FILE_CSV_TEMPERATURES)\n",
    "df_stations = pd.read_csv(FILE_CSV_STATIONS)\n",
    "df_country = pd.read_csv(FILE_CSV_COUNTRIES_CREATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    station_id  year  January_value  January_dm_flag January_qc_flag  \\\n",
      "0  ACW00011604  1961            -89              NaN             NaN   \n",
      "\n",
      "  January_ds_flag  February_value  February_dm_flag February_qc_flag  \\\n",
      "0               k             236               NaN              NaN   \n",
      "\n",
      "  February_ds_flag  ...  October_qc_flag  October_ds_flag November_value  \\\n",
      "0                k  ...              NaN                k            510   \n",
      "\n",
      "  November_dm_flag  November_qc_flag  November_ds_flag December_value  \\\n",
      "0              NaN               NaN                 k            -39   \n",
      "\n",
      "  December_dm_flag  December_qc_flag  December_ds_flag  \n",
      "0              NaN               NaN                 k  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "    station_id  latitude  longitude  station_elev station_name fips\n",
      "0  ACW00011604   57.7667    11.8667          18.0         SAVE   AC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  </th><th>station_id  </th><th style=\"text-align: right;\">  year</th><th>station_name  </th><th style=\"text-align: right;\">  latitude</th><th style=\"text-align: right;\">  longitude</th><th style=\"text-align: right;\">  station_elev</th><th>region  </th><th style=\"text-align: right;\">  January_value</th><th style=\"text-align: right;\">  February_value</th><th style=\"text-align: right;\">  March_value</th><th style=\"text-align: right;\">  April_value</th><th style=\"text-align: right;\">  May_value</th><th style=\"text-align: right;\">  June_value</th><th style=\"text-align: right;\">  July_value</th><th style=\"text-align: right;\">  August_value</th><th style=\"text-align: right;\">  September_value</th><th style=\"text-align: right;\">  October_value</th><th style=\"text-align: right;\">  November_value</th><th style=\"text-align: right;\">  December_value</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 0</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1961</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">            -89</td><td style=\"text-align: right;\">             236</td><td style=\"text-align: right;\">          472</td><td style=\"text-align: right;\">          773</td><td style=\"text-align: right;\">       1128</td><td style=\"text-align: right;\">        1599</td><td style=\"text-align: right;\">        1570</td><td style=\"text-align: right;\">          1481</td><td style=\"text-align: right;\">             1413</td><td style=\"text-align: right;\">           1174</td><td style=\"text-align: right;\">             510</td><td style=\"text-align: right;\">             -39</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 1</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1962</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">            113</td><td style=\"text-align: right;\">              85</td><td style=\"text-align: right;\">         -154</td><td style=\"text-align: right;\">          635</td><td style=\"text-align: right;\">        908</td><td style=\"text-align: right;\">        1381</td><td style=\"text-align: right;\">        1510</td><td style=\"text-align: right;\">          1393</td><td style=\"text-align: right;\">             1163</td><td style=\"text-align: right;\">            994</td><td style=\"text-align: right;\">             323</td><td style=\"text-align: right;\">            -126</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 2</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1963</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">           -713</td><td style=\"text-align: right;\">            -553</td><td style=\"text-align: right;\">          -99</td><td style=\"text-align: right;\">          541</td><td style=\"text-align: right;\">       1224</td><td style=\"text-align: right;\">        1627</td><td style=\"text-align: right;\">        1620</td><td style=\"text-align: right;\">          1596</td><td style=\"text-align: right;\">             1332</td><td style=\"text-align: right;\">            940</td><td style=\"text-align: right;\">             566</td><td style=\"text-align: right;\">            -108</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 3</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1964</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">             62</td><td style=\"text-align: right;\">             -85</td><td style=\"text-align: right;\">           55</td><td style=\"text-align: right;\">          738</td><td style=\"text-align: right;\">       1219</td><td style=\"text-align: right;\">        1442</td><td style=\"text-align: right;\">        1506</td><td style=\"text-align: right;\">          1557</td><td style=\"text-align: right;\">             1221</td><td style=\"text-align: right;\">            788</td><td style=\"text-align: right;\">             546</td><td style=\"text-align: right;\">             112</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 4</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1965</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">             44</td><td style=\"text-align: right;\">            -105</td><td style=\"text-align: right;\">           38</td><td style=\"text-align: right;\">          590</td><td style=\"text-align: right;\">        987</td><td style=\"text-align: right;\">        1500</td><td style=\"text-align: right;\">        1487</td><td style=\"text-align: right;\">          1477</td><td style=\"text-align: right;\">             1377</td><td style=\"text-align: right;\">            974</td><td style=\"text-align: right;\">              31</td><td style=\"text-align: right;\">            -178</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">  </th><th>station_id  </th><th style=\"text-align: right;\">  year</th><th>station_name  </th><th style=\"text-align: right;\">  latitude</th><th style=\"text-align: right;\">  longitude</th><th style=\"text-align: right;\">  station_elev</th><th>region  </th><th style=\"text-align: right;\">  January_value</th><th style=\"text-align: right;\">  February_value</th><th style=\"text-align: right;\">  March_value</th><th style=\"text-align: right;\">  April_value</th><th style=\"text-align: right;\">  May_value</th><th style=\"text-align: right;\">  June_value</th><th style=\"text-align: right;\">  July_value</th><th style=\"text-align: right;\">  August_value</th><th style=\"text-align: right;\">  September_value</th><th style=\"text-align: right;\">  October_value</th><th style=\"text-align: right;\">  November_value</th><th style=\"text-align: right;\">  December_value</th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\"> 0</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1961</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">            -89</td><td style=\"text-align: right;\">             236</td><td style=\"text-align: right;\">          472</td><td style=\"text-align: right;\">          773</td><td style=\"text-align: right;\">       1128</td><td style=\"text-align: right;\">        1599</td><td style=\"text-align: right;\">        1570</td><td style=\"text-align: right;\">          1481</td><td style=\"text-align: right;\">             1413</td><td style=\"text-align: right;\">           1174</td><td style=\"text-align: right;\">             510</td><td style=\"text-align: right;\">             -39</td></tr>\\n<tr><td style=\"text-align: right;\"> 1</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1962</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">            113</td><td style=\"text-align: right;\">              85</td><td style=\"text-align: right;\">         -154</td><td style=\"text-align: right;\">          635</td><td style=\"text-align: right;\">        908</td><td style=\"text-align: right;\">        1381</td><td style=\"text-align: right;\">        1510</td><td style=\"text-align: right;\">          1393</td><td style=\"text-align: right;\">             1163</td><td style=\"text-align: right;\">            994</td><td style=\"text-align: right;\">             323</td><td style=\"text-align: right;\">            -126</td></tr>\\n<tr><td style=\"text-align: right;\"> 2</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1963</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">           -713</td><td style=\"text-align: right;\">            -553</td><td style=\"text-align: right;\">          -99</td><td style=\"text-align: right;\">          541</td><td style=\"text-align: right;\">       1224</td><td style=\"text-align: right;\">        1627</td><td style=\"text-align: right;\">        1620</td><td style=\"text-align: right;\">          1596</td><td style=\"text-align: right;\">             1332</td><td style=\"text-align: right;\">            940</td><td style=\"text-align: right;\">             566</td><td style=\"text-align: right;\">            -108</td></tr>\\n<tr><td style=\"text-align: right;\"> 3</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1964</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">             62</td><td style=\"text-align: right;\">             -85</td><td style=\"text-align: right;\">           55</td><td style=\"text-align: right;\">          738</td><td style=\"text-align: right;\">       1219</td><td style=\"text-align: right;\">        1442</td><td style=\"text-align: right;\">        1506</td><td style=\"text-align: right;\">          1557</td><td style=\"text-align: right;\">             1221</td><td style=\"text-align: right;\">            788</td><td style=\"text-align: right;\">             546</td><td style=\"text-align: right;\">             112</td></tr>\\n<tr><td style=\"text-align: right;\"> 4</td><td>ACW00011604 </td><td style=\"text-align: right;\">  1965</td><td>SAVE          </td><td style=\"text-align: right;\">   57.7667</td><td style=\"text-align: right;\">    11.8667</td><td style=\"text-align: right;\">            18</td><td>Americas</td><td style=\"text-align: right;\">             44</td><td style=\"text-align: right;\">            -105</td><td style=\"text-align: right;\">           38</td><td style=\"text-align: right;\">          590</td><td style=\"text-align: right;\">        987</td><td style=\"text-align: right;\">        1500</td><td style=\"text-align: right;\">        1487</td><td style=\"text-align: right;\">          1477</td><td style=\"text-align: right;\">             1377</td><td style=\"text-align: right;\">            974</td><td style=\"text-align: right;\">              31</td><td style=\"text-align: right;\">            -178</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tabulate\n",
    "print(df_temperatues.head(1))\n",
    "print(df_stations.head(1))\n",
    "df_merged = df_temperatues.merge(df_stations, on='station_id')\n",
    "df_merged = df_merged.merge(df_country, on='fips')\n",
    "colonne = [\"station_id\", \"year\", \"station_name\", \"latitude\", \"longitude\", \"station_elev\", \"region\"] + [str(calendar.month_name[i]+\"_value\") for i in range(1,13)]\n",
    "df_merged = df_merged[colonne]\n",
    "\n",
    "table = tabulate.tabulate(df_merged.head(5), headers='keys', tablefmt='html')\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatues = pd.read_csv(FILE_CSV_TEMPERATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "January 1345254\n",
      "********\n",
      "February 1343882\n",
      "********\n",
      "March 1344461\n",
      "********\n",
      "April 1343911\n",
      "********\n",
      "May 1343542\n",
      "********\n",
      "June 1343284\n",
      "********\n",
      "July 1343262\n",
      "********\n",
      "August 1343136\n",
      "********\n",
      "September 1343876\n",
      "********\n",
      "October 1345043\n",
      "********\n",
      "November 1346056\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    month_name = calendar.month_name[i]\n",
    "    print(\"********\")\n",
    "    new_df  = df_temperatues\n",
    "    \n",
    "    \n",
    "    new_df[month_name+\"_qc_flag\"] = df_temperatues[month_name+\"_qc_flag\"].apply(lambda x: \"-\" if pd.isna(x) else x)\n",
    "    prova = new_df[new_df[month_name+\"_qc_flag\"] == \"-\"]\n",
    "   # lista = list(set(prova.to_list()))\n",
    "    print(month_name, len(prova))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for index, row in merged.iterrows():\n",
    "#     print(f\"{index:5}\", f\"{row['name']:50}\",row['fips'])\n",
    "\n",
    "\n",
    "# print(merged)\n",
    "\n",
    "df_stations = pd.read_csv(FILE_CSV_STATIONS)\n",
    "# print(len(pd.unique(df_stations['fips'])))\n",
    "\n",
    "merged2 = df_stations.merge(merged, how='left', on='fips')\n",
    "# merged2 = merged2.drop(['name_country', 'region', 'sub-region', 'region-code', 'sub-region-code'], axis=1)\n",
    "merged2 = merged2.drop_duplicates() \n",
    "merged2 = merged2.reset_index()\n",
    "\n",
    "# print(merged2)\n",
    "for index, row in merged2.iterrows():\n",
    "    print(str(row).replace(\"\\n\",\"\\t\",-1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a29d3b88d3d770f4c6b76b3f467a825cd9493448f3062cde152f1e267121f11d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
